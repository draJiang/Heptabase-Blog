{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport { ok as assert } from 'uvu/assert';\nimport { asciiAlpha, asciiAlphanumeric, asciiControl, asciiDigit, markdownLineEndingOrSpace, markdownLineEnding, unicodePunctuation, unicodeWhitespace } from 'micromark-util-character';\nimport { codes } from 'micromark-util-symbol/codes.js';\nconst www = {\n  tokenize: tokenizeWww,\n  partial: true\n};\nconst domain = {\n  tokenize: tokenizeDomain,\n  partial: true\n};\nconst path = {\n  tokenize: tokenizePath,\n  partial: true\n};\nconst punctuation = {\n  tokenize: tokenizePunctuation,\n  partial: true\n};\nconst namedCharacterReference = {\n  tokenize: tokenizeNamedCharacterReference,\n  partial: true\n};\nconst wwwAutolink = {\n  tokenize: tokenizeWwwAutolink,\n  previous: previousWww\n};\nconst httpAutolink = {\n  tokenize: tokenizeHttpAutolink,\n  previous: previousHttp\n};\nconst emailAutolink = {\n  tokenize: tokenizeEmailAutolink,\n  previous: previousEmail\n};\n\n/** @type {ConstructRecord} */\nconst text = {};\n\n/** @type {Extension} */\nexport const gfmAutolinkLiteral = {\n  text\n};\nlet code = codes.digit0;\n\n// Add alphanumerics.\nwhile (code < codes.leftCurlyBrace) {\n  text[code] = emailAutolink;\n  code++;\n  if (code === codes.colon) code = codes.uppercaseA;else if (code === codes.leftSquareBracket) code = codes.lowercaseA;\n}\ntext[codes.plusSign] = emailAutolink;\ntext[codes.dash] = emailAutolink;\ntext[codes.dot] = emailAutolink;\ntext[codes.underscore] = emailAutolink;\ntext[codes.uppercaseH] = [emailAutolink, httpAutolink];\ntext[codes.lowercaseH] = [emailAutolink, httpAutolink];\ntext[codes.uppercaseW] = [emailAutolink, wwwAutolink];\ntext[codes.lowercaseW] = [emailAutolink, wwwAutolink];\n\n/** @type {Tokenizer} */\nfunction tokenizeEmailAutolink(effects, ok, nok) {\n  const self = this;\n  /** @type {boolean} */\n  let hasDot;\n  /** @type {boolean|undefined} */\n  let hasDigitInLastSegment;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    if (!gfmAtext(code) || !previousEmail(self.previous) || previousUnbalanced(self.events)) {\n      return nok(code);\n    }\n    effects.enter('literalAutolink');\n    effects.enter('literalAutolinkEmail');\n    return atext(code);\n  }\n\n  /** @type {State} */\n  function atext(code) {\n    if (gfmAtext(code)) {\n      effects.consume(code);\n      return atext;\n    }\n    if (code === codes.atSign) {\n      effects.consume(code);\n      return label;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function label(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, done, dotContinuation)(code);\n    }\n    if (code === codes.dash || code === codes.underscore) {\n      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code);\n    }\n    if (asciiAlphanumeric(code)) {\n      if (!hasDigitInLastSegment && asciiDigit(code)) {\n        hasDigitInLastSegment = true;\n      }\n      effects.consume(code);\n      return label;\n    }\n    return done(code);\n  }\n\n  /** @type {State} */\n  function dotContinuation(code) {\n    effects.consume(code);\n    hasDot = true;\n    hasDigitInLastSegment = undefined;\n    return label;\n  }\n\n  /** @type {State} */\n  function dashOrUnderscoreContinuation(code) {\n    effects.consume(code);\n    return afterDashOrUnderscore;\n  }\n\n  /** @type {State} */\n  function afterDashOrUnderscore(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, nok, dotContinuation)(code);\n    }\n    return label(code);\n  }\n\n  /** @type {State} */\n  function done(code) {\n    if (hasDot && !hasDigitInLastSegment) {\n      effects.exit('literalAutolinkEmail');\n      effects.exit('literalAutolink');\n      return ok(code);\n    }\n    return nok(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeWwwAutolink(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    if (code !== codes.uppercaseW && code !== codes.lowercaseW || !previousWww(self.previous) || previousUnbalanced(self.events)) {\n      return nok(code);\n    }\n    effects.enter('literalAutolink');\n    effects.enter('literalAutolinkWww');\n    // For `www.` we check instead of attempt, because when it matches, GH\n    // treats it as part of a domain (yes, it says a valid domain must come\n    // after `www.`, but that’s not how it’s implemented by them).\n    return effects.check(www, effects.attempt(domain, effects.attempt(path, done), nok), nok)(code);\n  }\n\n  /** @type {State} */\n  function done(code) {\n    effects.exit('literalAutolinkWww');\n    effects.exit('literalAutolink');\n    return ok(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeHttpAutolink(effects, ok, nok) {\n  const self = this;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    if (code !== codes.uppercaseH && code !== codes.lowercaseH || !previousHttp(self.previous) || previousUnbalanced(self.events)) {\n      return nok(code);\n    }\n    effects.enter('literalAutolink');\n    effects.enter('literalAutolinkHttp');\n    effects.consume(code);\n    return t1;\n  }\n\n  /** @type {State} */\n  function t1(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code);\n      return t2;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function t2(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code);\n      return p;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function p(code) {\n    if (code === codes.uppercaseP || code === codes.lowercaseP) {\n      effects.consume(code);\n      return s;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function s(code) {\n    if (code === codes.uppercaseS || code === codes.lowercaseS) {\n      effects.consume(code);\n      return colon;\n    }\n    return colon(code);\n  }\n\n  /** @type {State} */\n  function colon(code) {\n    if (code === codes.colon) {\n      effects.consume(code);\n      return slash1;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function slash1(code) {\n    if (code === codes.slash) {\n      effects.consume(code);\n      return slash2;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function slash2(code) {\n    if (code === codes.slash) {\n      effects.consume(code);\n      return after;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function after(code) {\n    return code === codes.eof || asciiControl(code) || unicodeWhitespace(code) || unicodePunctuation(code) ? nok(code) : effects.attempt(domain, effects.attempt(path, done), nok)(code);\n  }\n\n  /** @type {State} */\n  function done(code) {\n    effects.exit('literalAutolinkHttp');\n    effects.exit('literalAutolink');\n    return ok(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeWww(effects, ok, nok) {\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    assert(code === codes.uppercaseW || code === codes.lowercaseW, 'expected `w`');\n    effects.consume(code);\n    return w2;\n  }\n\n  /** @type {State} */\n  function w2(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code);\n      return w3;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function w3(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code);\n      return dot;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function dot(code) {\n    if (code === codes.dot) {\n      effects.consume(code);\n      return after;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function after(code) {\n    return code === codes.eof || markdownLineEnding(code) ? nok(code) : ok(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeDomain(effects, ok, nok) {\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastSegment;\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastLastSegment;\n  return domain;\n\n  /** @type {State} */\n  function domain(code) {\n    if (code === codes.ampersand) {\n      return effects.check(namedCharacterReference, done, punctuationContinuation)(code);\n    }\n    if (code === codes.dot || code === codes.underscore) {\n      return effects.check(punctuation, done, punctuationContinuation)(code);\n    }\n\n    // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can\n    // occur, which sounds like ASCII only, but they also support `www.點看.com`,\n    // so that’s Unicode.\n    // Instead of some new production for Unicode alphanumerics, markdown\n    // already has that for Unicode punctuation and whitespace, so use those.\n    if (code === codes.eof || asciiControl(code) || unicodeWhitespace(code) || code !== codes.dash && unicodePunctuation(code)) {\n      return done(code);\n    }\n    effects.consume(code);\n    return domain;\n  }\n\n  /** @type {State} */\n  function punctuationContinuation(code) {\n    if (code === codes.dot) {\n      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment;\n      hasUnderscoreInLastSegment = undefined;\n      effects.consume(code);\n      return domain;\n    }\n    if (code === codes.underscore) hasUnderscoreInLastSegment = true;\n    effects.consume(code);\n    return domain;\n  }\n\n  /** @type {State} */\n  function done(code) {\n    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {\n      return ok(code);\n    }\n    return nok(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizePath(effects, ok) {\n  let balance = 0;\n  return inPath;\n\n  /** @type {State} */\n  function inPath(code) {\n    if (code === codes.ampersand) {\n      return effects.check(namedCharacterReference, ok, continuedPunctuation)(code);\n    }\n    if (code === codes.leftParenthesis) {\n      balance++;\n    }\n    if (code === codes.rightParenthesis) {\n      return effects.check(punctuation, parenAtPathEnd, continuedPunctuation)(code);\n    }\n    if (pathEnd(code)) {\n      return ok(code);\n    }\n    if (trailingPunctuation(code)) {\n      return effects.check(punctuation, ok, continuedPunctuation)(code);\n    }\n    effects.consume(code);\n    return inPath;\n  }\n\n  /** @type {State} */\n  function continuedPunctuation(code) {\n    effects.consume(code);\n    return inPath;\n  }\n\n  /** @type {State} */\n  function parenAtPathEnd(code) {\n    balance--;\n    return balance < 0 ? ok(code) : continuedPunctuation(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeNamedCharacterReference(effects, ok, nok) {\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    assert(code === codes.ampersand, 'expected `&`');\n    effects.consume(code);\n    return inside;\n  }\n\n  /** @type {State} */\n  function inside(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code);\n      return inside;\n    }\n    if (code === codes.semicolon) {\n      effects.consume(code);\n      return after;\n    }\n    return nok(code);\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // If the named character reference is followed by the end of the path, it’s\n    // not continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code);\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizePunctuation(effects, ok, nok) {\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    assert(code === codes.dash || trailingPunctuation(code), 'expected punctuation');\n    effects.consume(code);\n    return after;\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // Check the next.\n    if (trailingPunctuation(code)) {\n      effects.consume(code);\n      return after;\n    }\n\n    // If the punctuation marker is followed by the end of the path, it’s not\n    // continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code);\n  }\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction trailingPunctuation(code) {\n  return code === codes.exclamationMark || code === codes.quotationMark || code === codes.apostrophe || code === codes.rightParenthesis || code === codes.asterisk || code === codes.comma || code === codes.dot || code === codes.colon || code === codes.semicolon || code === codes.lessThan || code === codes.questionMark || code === codes.underscore || code === codes.tilde;\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction pathEnd(code) {\n  return code === codes.eof || code === codes.lessThan || markdownLineEndingOrSpace(code);\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction gfmAtext(code) {\n  return code === codes.plusSign || code === codes.dash || code === codes.dot || code === codes.underscore || asciiAlphanumeric(code);\n}\n\n/** @type {Previous} */\nfunction previousWww(code) {\n  return code === codes.eof || code === codes.leftParenthesis || code === codes.asterisk || code === codes.underscore || code === codes.tilde || markdownLineEndingOrSpace(code);\n}\n\n/** @type {Previous} */\nfunction previousHttp(code) {\n  return code === codes.eof || !asciiAlpha(code);\n}\n\n/** @type {Previous} */\nfunction previousEmail(code) {\n  return code !== codes.slash && previousHttp(code);\n}\n\n/**\n * @param {Array<Event>} events\n * @returns {boolean}\n */\nfunction previousUnbalanced(events) {\n  let index = events.length;\n  let result = false;\n  while (index--) {\n    const token = events[index][1];\n    if ((token.type === 'labelLink' || token.type === 'labelImage') && !token._balanced) {\n      result = true;\n      break;\n    }\n\n    // @ts-expect-error If we’ve seen this token, and it was marked as not\n    // having any unbalanced bracket before it, we can exit.\n    if (token._gfmAutolinkLiteralWalkedInto) {\n      result = false;\n      break;\n    }\n  }\n  if (events.length > 0 && !result) {\n    // @ts-expect-error Mark the last token as “walked into” w/o finding\n    // anything.\n    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true;\n  }\n  return result;\n}","map":{"version":3,"names":["ok","assert","asciiAlpha","asciiAlphanumeric","asciiControl","asciiDigit","markdownLineEndingOrSpace","markdownLineEnding","unicodePunctuation","unicodeWhitespace","codes","www","tokenize","tokenizeWww","partial","domain","tokenizeDomain","path","tokenizePath","punctuation","tokenizePunctuation","namedCharacterReference","tokenizeNamedCharacterReference","wwwAutolink","tokenizeWwwAutolink","previous","previousWww","httpAutolink","tokenizeHttpAutolink","previousHttp","emailAutolink","tokenizeEmailAutolink","previousEmail","text","gfmAutolinkLiteral","code","digit0","leftCurlyBrace","colon","uppercaseA","leftSquareBracket","lowercaseA","plusSign","dash","dot","underscore","uppercaseH","lowercaseH","uppercaseW","lowercaseW","effects","nok","self","hasDot","hasDigitInLastSegment","start","gfmAtext","previousUnbalanced","events","enter","atext","consume","atSign","label","check","done","dotContinuation","dashOrUnderscoreContinuation","undefined","afterDashOrUnderscore","exit","attempt","t1","uppercaseT","lowercaseT","t2","p","uppercaseP","lowercaseP","s","uppercaseS","lowercaseS","slash1","slash","slash2","after","eof","w2","w3","hasUnderscoreInLastSegment","hasUnderscoreInLastLastSegment","ampersand","punctuationContinuation","balance","inPath","continuedPunctuation","leftParenthesis","rightParenthesis","parenAtPathEnd","pathEnd","trailingPunctuation","inside","semicolon","exclamationMark","quotationMark","apostrophe","asterisk","comma","lessThan","questionMark","tilde","index","length","result","token","type","_balanced","_gfmAutolinkLiteralWalkedInto"],"sources":["/Users/jiangzilong/学习/minpg/Heptabase-Blog/node_modules/micromark-extension-gfm-autolink-literal/dev/lib/syntax.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Code} Code\n */\n\nimport {ok as assert} from 'uvu/assert'\nimport {\n  asciiAlpha,\n  asciiAlphanumeric,\n  asciiControl,\n  asciiDigit,\n  markdownLineEndingOrSpace,\n  markdownLineEnding,\n  unicodePunctuation,\n  unicodeWhitespace\n} from 'micromark-util-character'\nimport {codes} from 'micromark-util-symbol/codes.js'\n\nconst www = {tokenize: tokenizeWww, partial: true}\nconst domain = {tokenize: tokenizeDomain, partial: true}\nconst path = {tokenize: tokenizePath, partial: true}\nconst punctuation = {tokenize: tokenizePunctuation, partial: true}\nconst namedCharacterReference = {\n  tokenize: tokenizeNamedCharacterReference,\n  partial: true\n}\n\nconst wwwAutolink = {tokenize: tokenizeWwwAutolink, previous: previousWww}\nconst httpAutolink = {tokenize: tokenizeHttpAutolink, previous: previousHttp}\nconst emailAutolink = {tokenize: tokenizeEmailAutolink, previous: previousEmail}\n\n/** @type {ConstructRecord} */\nconst text = {}\n\n/** @type {Extension} */\nexport const gfmAutolinkLiteral = {text}\n\nlet code = codes.digit0\n\n// Add alphanumerics.\nwhile (code < codes.leftCurlyBrace) {\n  text[code] = emailAutolink\n  code++\n  if (code === codes.colon) code = codes.uppercaseA\n  else if (code === codes.leftSquareBracket) code = codes.lowercaseA\n}\n\ntext[codes.plusSign] = emailAutolink\ntext[codes.dash] = emailAutolink\ntext[codes.dot] = emailAutolink\ntext[codes.underscore] = emailAutolink\ntext[codes.uppercaseH] = [emailAutolink, httpAutolink]\ntext[codes.lowercaseH] = [emailAutolink, httpAutolink]\ntext[codes.uppercaseW] = [emailAutolink, wwwAutolink]\ntext[codes.lowercaseW] = [emailAutolink, wwwAutolink]\n\n/** @type {Tokenizer} */\nfunction tokenizeEmailAutolink(effects, ok, nok) {\n  const self = this\n  /** @type {boolean} */\n  let hasDot\n  /** @type {boolean|undefined} */\n  let hasDigitInLastSegment\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    if (\n      !gfmAtext(code) ||\n      !previousEmail(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkEmail')\n    return atext(code)\n  }\n\n  /** @type {State} */\n  function atext(code) {\n    if (gfmAtext(code)) {\n      effects.consume(code)\n      return atext\n    }\n\n    if (code === codes.atSign) {\n      effects.consume(code)\n      return label\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function label(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, done, dotContinuation)(code)\n    }\n\n    if (code === codes.dash || code === codes.underscore) {\n      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code)\n    }\n\n    if (asciiAlphanumeric(code)) {\n      if (!hasDigitInLastSegment && asciiDigit(code)) {\n        hasDigitInLastSegment = true\n      }\n\n      effects.consume(code)\n      return label\n    }\n\n    return done(code)\n  }\n\n  /** @type {State} */\n  function dotContinuation(code) {\n    effects.consume(code)\n    hasDot = true\n    hasDigitInLastSegment = undefined\n    return label\n  }\n\n  /** @type {State} */\n  function dashOrUnderscoreContinuation(code) {\n    effects.consume(code)\n    return afterDashOrUnderscore\n  }\n\n  /** @type {State} */\n  function afterDashOrUnderscore(code) {\n    if (code === codes.dot) {\n      return effects.check(punctuation, nok, dotContinuation)(code)\n    }\n\n    return label(code)\n  }\n\n  /** @type {State} */\n  function done(code) {\n    if (hasDot && !hasDigitInLastSegment) {\n      effects.exit('literalAutolinkEmail')\n      effects.exit('literalAutolink')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeWwwAutolink(effects, ok, nok) {\n  const self = this\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    if (\n      (code !== codes.uppercaseW && code !== codes.lowercaseW) ||\n      !previousWww(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkWww')\n    // For `www.` we check instead of attempt, because when it matches, GH\n    // treats it as part of a domain (yes, it says a valid domain must come\n    // after `www.`, but that’s not how it’s implemented by them).\n    return effects.check(\n      www,\n      effects.attempt(domain, effects.attempt(path, done), nok),\n      nok\n    )(code)\n  }\n\n  /** @type {State} */\n  function done(code) {\n    effects.exit('literalAutolinkWww')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeHttpAutolink(effects, ok, nok) {\n  const self = this\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    if (\n      (code !== codes.uppercaseH && code !== codes.lowercaseH) ||\n      !previousHttp(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkHttp')\n    effects.consume(code)\n    return t1\n  }\n\n  /** @type {State} */\n  function t1(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code)\n      return t2\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function t2(code) {\n    if (code === codes.uppercaseT || code === codes.lowercaseT) {\n      effects.consume(code)\n      return p\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function p(code) {\n    if (code === codes.uppercaseP || code === codes.lowercaseP) {\n      effects.consume(code)\n      return s\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function s(code) {\n    if (code === codes.uppercaseS || code === codes.lowercaseS) {\n      effects.consume(code)\n      return colon\n    }\n\n    return colon(code)\n  }\n\n  /** @type {State} */\n  function colon(code) {\n    if (code === codes.colon) {\n      effects.consume(code)\n      return slash1\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function slash1(code) {\n    if (code === codes.slash) {\n      effects.consume(code)\n      return slash2\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function slash2(code) {\n    if (code === codes.slash) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function after(code) {\n    return code === codes.eof ||\n      asciiControl(code) ||\n      unicodeWhitespace(code) ||\n      unicodePunctuation(code)\n      ? nok(code)\n      : effects.attempt(domain, effects.attempt(path, done), nok)(code)\n  }\n\n  /** @type {State} */\n  function done(code) {\n    effects.exit('literalAutolinkHttp')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeWww(effects, ok, nok) {\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(\n      code === codes.uppercaseW || code === codes.lowercaseW,\n      'expected `w`'\n    )\n    effects.consume(code)\n    return w2\n  }\n\n  /** @type {State} */\n  function w2(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code)\n      return w3\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function w3(code) {\n    if (code === codes.uppercaseW || code === codes.lowercaseW) {\n      effects.consume(code)\n      return dot\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function dot(code) {\n    if (code === codes.dot) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function after(code) {\n    return code === codes.eof || markdownLineEnding(code) ? nok(code) : ok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeDomain(effects, ok, nok) {\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastSegment\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastLastSegment\n\n  return domain\n\n  /** @type {State} */\n  function domain(code) {\n    if (code === codes.ampersand) {\n      return effects.check(\n        namedCharacterReference,\n        done,\n        punctuationContinuation\n      )(code)\n    }\n\n    if (code === codes.dot || code === codes.underscore) {\n      return effects.check(punctuation, done, punctuationContinuation)(code)\n    }\n\n    // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can\n    // occur, which sounds like ASCII only, but they also support `www.點看.com`,\n    // so that’s Unicode.\n    // Instead of some new production for Unicode alphanumerics, markdown\n    // already has that for Unicode punctuation and whitespace, so use those.\n    if (\n      code === codes.eof ||\n      asciiControl(code) ||\n      unicodeWhitespace(code) ||\n      (code !== codes.dash && unicodePunctuation(code))\n    ) {\n      return done(code)\n    }\n\n    effects.consume(code)\n    return domain\n  }\n\n  /** @type {State} */\n  function punctuationContinuation(code) {\n    if (code === codes.dot) {\n      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment\n      hasUnderscoreInLastSegment = undefined\n      effects.consume(code)\n      return domain\n    }\n\n    if (code === codes.underscore) hasUnderscoreInLastSegment = true\n\n    effects.consume(code)\n    return domain\n  }\n\n  /** @type {State} */\n  function done(code) {\n    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizePath(effects, ok) {\n  let balance = 0\n\n  return inPath\n\n  /** @type {State} */\n  function inPath(code) {\n    if (code === codes.ampersand) {\n      return effects.check(\n        namedCharacterReference,\n        ok,\n        continuedPunctuation\n      )(code)\n    }\n\n    if (code === codes.leftParenthesis) {\n      balance++\n    }\n\n    if (code === codes.rightParenthesis) {\n      return effects.check(\n        punctuation,\n        parenAtPathEnd,\n        continuedPunctuation\n      )(code)\n    }\n\n    if (pathEnd(code)) {\n      return ok(code)\n    }\n\n    if (trailingPunctuation(code)) {\n      return effects.check(punctuation, ok, continuedPunctuation)(code)\n    }\n\n    effects.consume(code)\n    return inPath\n  }\n\n  /** @type {State} */\n  function continuedPunctuation(code) {\n    effects.consume(code)\n    return inPath\n  }\n\n  /** @type {State} */\n  function parenAtPathEnd(code) {\n    balance--\n    return balance < 0 ? ok(code) : continuedPunctuation(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeNamedCharacterReference(effects, ok, nok) {\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(code === codes.ampersand, 'expected `&`')\n    effects.consume(code)\n    return inside\n  }\n\n  /** @type {State} */\n  function inside(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return inside\n    }\n\n    if (code === codes.semicolon) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // If the named character reference is followed by the end of the path, it’s\n    // not continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code)\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizePunctuation(effects, ok, nok) {\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(\n      code === codes.dash || trailingPunctuation(code),\n      'expected punctuation'\n    )\n    effects.consume(code)\n    return after\n  }\n\n  /** @type {State} */\n  function after(code) {\n    // Check the next.\n    if (trailingPunctuation(code)) {\n      effects.consume(code)\n      return after\n    }\n\n    // If the punctuation marker is followed by the end of the path, it’s not\n    // continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code)\n  }\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction trailingPunctuation(code) {\n  return (\n    code === codes.exclamationMark ||\n    code === codes.quotationMark ||\n    code === codes.apostrophe ||\n    code === codes.rightParenthesis ||\n    code === codes.asterisk ||\n    code === codes.comma ||\n    code === codes.dot ||\n    code === codes.colon ||\n    code === codes.semicolon ||\n    code === codes.lessThan ||\n    code === codes.questionMark ||\n    code === codes.underscore ||\n    code === codes.tilde\n  )\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction pathEnd(code) {\n  return (\n    code === codes.eof ||\n    code === codes.lessThan ||\n    markdownLineEndingOrSpace(code)\n  )\n}\n\n/**\n * @param {Code} code\n * @returns {boolean}\n */\nfunction gfmAtext(code) {\n  return (\n    code === codes.plusSign ||\n    code === codes.dash ||\n    code === codes.dot ||\n    code === codes.underscore ||\n    asciiAlphanumeric(code)\n  )\n}\n\n/** @type {Previous} */\nfunction previousWww(code) {\n  return (\n    code === codes.eof ||\n    code === codes.leftParenthesis ||\n    code === codes.asterisk ||\n    code === codes.underscore ||\n    code === codes.tilde ||\n    markdownLineEndingOrSpace(code)\n  )\n}\n\n/** @type {Previous} */\nfunction previousHttp(code) {\n  return code === codes.eof || !asciiAlpha(code)\n}\n\n/** @type {Previous} */\nfunction previousEmail(code) {\n  return code !== codes.slash && previousHttp(code)\n}\n\n/**\n * @param {Array<Event>} events\n * @returns {boolean}\n */\nfunction previousUnbalanced(events) {\n  let index = events.length\n  let result = false\n\n  while (index--) {\n    const token = events[index][1]\n\n    if (\n      (token.type === 'labelLink' || token.type === 'labelImage') &&\n      !token._balanced\n    ) {\n      result = true\n      break\n    }\n\n    // @ts-expect-error If we’ve seen this token, and it was marked as not\n    // having any unbalanced bracket before it, we can exit.\n    if (token._gfmAutolinkLiteralWalkedInto) {\n      result = false\n      break\n    }\n  }\n\n  if (events.length > 0 && !result) {\n    // @ts-expect-error Mark the last token as “walked into” w/o finding\n    // anything.\n    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true\n  }\n\n  return result\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAQA,EAAE,IAAIC,MAAM,QAAO,YAAY;AACvC,SACEC,UAAU,EACVC,iBAAiB,EACjBC,YAAY,EACZC,UAAU,EACVC,yBAAyB,EACzBC,kBAAkB,EAClBC,kBAAkB,EAClBC,iBAAiB,QACZ,0BAA0B;AACjC,SAAQC,KAAK,QAAO,gCAAgC;AAEpD,MAAMC,GAAG,GAAG;EAACC,QAAQ,EAAEC,WAAW;EAAEC,OAAO,EAAE;AAAI,CAAC;AAClD,MAAMC,MAAM,GAAG;EAACH,QAAQ,EAAEI,cAAc;EAAEF,OAAO,EAAE;AAAI,CAAC;AACxD,MAAMG,IAAI,GAAG;EAACL,QAAQ,EAAEM,YAAY;EAAEJ,OAAO,EAAE;AAAI,CAAC;AACpD,MAAMK,WAAW,GAAG;EAACP,QAAQ,EAAEQ,mBAAmB;EAAEN,OAAO,EAAE;AAAI,CAAC;AAClE,MAAMO,uBAAuB,GAAG;EAC9BT,QAAQ,EAAEU,+BAA+B;EACzCR,OAAO,EAAE;AACX,CAAC;AAED,MAAMS,WAAW,GAAG;EAACX,QAAQ,EAAEY,mBAAmB;EAAEC,QAAQ,EAAEC;AAAW,CAAC;AAC1E,MAAMC,YAAY,GAAG;EAACf,QAAQ,EAAEgB,oBAAoB;EAAEH,QAAQ,EAAEI;AAAY,CAAC;AAC7E,MAAMC,aAAa,GAAG;EAAClB,QAAQ,EAAEmB,qBAAqB;EAAEN,QAAQ,EAAEO;AAAa,CAAC;;AAEhF;AACA,MAAMC,IAAI,GAAG,CAAC,CAAC;;AAEf;AACA,OAAO,MAAMC,kBAAkB,GAAG;EAACD;AAAI,CAAC;AAExC,IAAIE,IAAI,GAAGzB,KAAK,CAAC0B,MAAM;;AAEvB;AACA,OAAOD,IAAI,GAAGzB,KAAK,CAAC2B,cAAc,EAAE;EAClCJ,IAAI,CAACE,IAAI,CAAC,GAAGL,aAAa;EAC1BK,IAAI,EAAE;EACN,IAAIA,IAAI,KAAKzB,KAAK,CAAC4B,KAAK,EAAEH,IAAI,GAAGzB,KAAK,CAAC6B,UAAU,MAC5C,IAAIJ,IAAI,KAAKzB,KAAK,CAAC8B,iBAAiB,EAAEL,IAAI,GAAGzB,KAAK,CAAC+B,UAAU;AACpE;AAEAR,IAAI,CAACvB,KAAK,CAACgC,QAAQ,CAAC,GAAGZ,aAAa;AACpCG,IAAI,CAACvB,KAAK,CAACiC,IAAI,CAAC,GAAGb,aAAa;AAChCG,IAAI,CAACvB,KAAK,CAACkC,GAAG,CAAC,GAAGd,aAAa;AAC/BG,IAAI,CAACvB,KAAK,CAACmC,UAAU,CAAC,GAAGf,aAAa;AACtCG,IAAI,CAACvB,KAAK,CAACoC,UAAU,CAAC,GAAG,CAAChB,aAAa,EAAEH,YAAY,CAAC;AACtDM,IAAI,CAACvB,KAAK,CAACqC,UAAU,CAAC,GAAG,CAACjB,aAAa,EAAEH,YAAY,CAAC;AACtDM,IAAI,CAACvB,KAAK,CAACsC,UAAU,CAAC,GAAG,CAAClB,aAAa,EAAEP,WAAW,CAAC;AACrDU,IAAI,CAACvB,KAAK,CAACuC,UAAU,CAAC,GAAG,CAACnB,aAAa,EAAEP,WAAW,CAAC;;AAErD;AACA,SAASQ,qBAAqB,CAACmB,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EAC/C,MAAMC,IAAI,GAAG,IAAI;EACjB;EACA,IAAIC,MAAM;EACV;EACA,IAAIC,qBAAqB;EAEzB,OAAOC,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACpB,IAAI,EAAE;IACnB,IACE,CAACqB,QAAQ,CAACrB,IAAI,CAAC,IACf,CAACH,aAAa,CAACoB,IAAI,CAAC3B,QAAQ,CAAC,IAC7BgC,kBAAkB,CAACL,IAAI,CAACM,MAAM,CAAC,EAC/B;MACA,OAAOP,GAAG,CAAChB,IAAI,CAAC;IAClB;IAEAe,OAAO,CAACS,KAAK,CAAC,iBAAiB,CAAC;IAChCT,OAAO,CAACS,KAAK,CAAC,sBAAsB,CAAC;IACrC,OAAOC,KAAK,CAACzB,IAAI,CAAC;EACpB;;EAEA;EACA,SAASyB,KAAK,CAACzB,IAAI,EAAE;IACnB,IAAIqB,QAAQ,CAACrB,IAAI,CAAC,EAAE;MAClBe,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOyB,KAAK;IACd;IAEA,IAAIzB,IAAI,KAAKzB,KAAK,CAACoD,MAAM,EAAE;MACzBZ,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAO4B,KAAK;IACd;IAEA,OAAOZ,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAAS4B,KAAK,CAAC5B,IAAI,EAAE;IACnB,IAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAG,EAAE;MACtB,OAAOM,OAAO,CAACc,KAAK,CAAC7C,WAAW,EAAE8C,IAAI,EAAEC,eAAe,CAAC,CAAC/B,IAAI,CAAC;IAChE;IAEA,IAAIA,IAAI,KAAKzB,KAAK,CAACiC,IAAI,IAAIR,IAAI,KAAKzB,KAAK,CAACmC,UAAU,EAAE;MACpD,OAAOK,OAAO,CAACc,KAAK,CAAC7C,WAAW,EAAEgC,GAAG,EAAEgB,4BAA4B,CAAC,CAAChC,IAAI,CAAC;IAC5E;IAEA,IAAIhC,iBAAiB,CAACgC,IAAI,CAAC,EAAE;MAC3B,IAAI,CAACmB,qBAAqB,IAAIjD,UAAU,CAAC8B,IAAI,CAAC,EAAE;QAC9CmB,qBAAqB,GAAG,IAAI;MAC9B;MAEAJ,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAO4B,KAAK;IACd;IAEA,OAAOE,IAAI,CAAC9B,IAAI,CAAC;EACnB;;EAEA;EACA,SAAS+B,eAAe,CAAC/B,IAAI,EAAE;IAC7Be,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrBkB,MAAM,GAAG,IAAI;IACbC,qBAAqB,GAAGc,SAAS;IACjC,OAAOL,KAAK;EACd;;EAEA;EACA,SAASI,4BAA4B,CAAChC,IAAI,EAAE;IAC1Ce,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOkC,qBAAqB;EAC9B;;EAEA;EACA,SAASA,qBAAqB,CAAClC,IAAI,EAAE;IACnC,IAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAG,EAAE;MACtB,OAAOM,OAAO,CAACc,KAAK,CAAC7C,WAAW,EAAEgC,GAAG,EAAEe,eAAe,CAAC,CAAC/B,IAAI,CAAC;IAC/D;IAEA,OAAO4B,KAAK,CAAC5B,IAAI,CAAC;EACpB;;EAEA;EACA,SAAS8B,IAAI,CAAC9B,IAAI,EAAE;IAClB,IAAIkB,MAAM,IAAI,CAACC,qBAAqB,EAAE;MACpCJ,OAAO,CAACoB,IAAI,CAAC,sBAAsB,CAAC;MACpCpB,OAAO,CAACoB,IAAI,CAAC,iBAAiB,CAAC;MAC/B,OAAOtE,EAAE,CAACmC,IAAI,CAAC;IACjB;IAEA,OAAOgB,GAAG,CAAChB,IAAI,CAAC;EAClB;AACF;;AAEA;AACA,SAASX,mBAAmB,CAAC0B,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EAC7C,MAAMC,IAAI,GAAG,IAAI;EAEjB,OAAOG,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACpB,IAAI,EAAE;IACnB,IACGA,IAAI,KAAKzB,KAAK,CAACsC,UAAU,IAAIb,IAAI,KAAKzB,KAAK,CAACuC,UAAU,IACvD,CAACvB,WAAW,CAAC0B,IAAI,CAAC3B,QAAQ,CAAC,IAC3BgC,kBAAkB,CAACL,IAAI,CAACM,MAAM,CAAC,EAC/B;MACA,OAAOP,GAAG,CAAChB,IAAI,CAAC;IAClB;IAEAe,OAAO,CAACS,KAAK,CAAC,iBAAiB,CAAC;IAChCT,OAAO,CAACS,KAAK,CAAC,oBAAoB,CAAC;IACnC;IACA;IACA;IACA,OAAOT,OAAO,CAACc,KAAK,CAClBrD,GAAG,EACHuC,OAAO,CAACqB,OAAO,CAACxD,MAAM,EAAEmC,OAAO,CAACqB,OAAO,CAACtD,IAAI,EAAEgD,IAAI,CAAC,EAAEd,GAAG,CAAC,EACzDA,GAAG,CACJ,CAAChB,IAAI,CAAC;EACT;;EAEA;EACA,SAAS8B,IAAI,CAAC9B,IAAI,EAAE;IAClBe,OAAO,CAACoB,IAAI,CAAC,oBAAoB,CAAC;IAClCpB,OAAO,CAACoB,IAAI,CAAC,iBAAiB,CAAC;IAC/B,OAAOtE,EAAE,CAACmC,IAAI,CAAC;EACjB;AACF;;AAEA;AACA,SAASP,oBAAoB,CAACsB,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EAC9C,MAAMC,IAAI,GAAG,IAAI;EAEjB,OAAOG,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACpB,IAAI,EAAE;IACnB,IACGA,IAAI,KAAKzB,KAAK,CAACoC,UAAU,IAAIX,IAAI,KAAKzB,KAAK,CAACqC,UAAU,IACvD,CAAClB,YAAY,CAACuB,IAAI,CAAC3B,QAAQ,CAAC,IAC5BgC,kBAAkB,CAACL,IAAI,CAACM,MAAM,CAAC,EAC/B;MACA,OAAOP,GAAG,CAAChB,IAAI,CAAC;IAClB;IAEAe,OAAO,CAACS,KAAK,CAAC,iBAAiB,CAAC;IAChCT,OAAO,CAACS,KAAK,CAAC,qBAAqB,CAAC;IACpCT,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOqC,EAAE;EACX;;EAEA;EACA,SAASA,EAAE,CAACrC,IAAI,EAAE;IAChB,IAAIA,IAAI,KAAKzB,KAAK,CAAC+D,UAAU,IAAItC,IAAI,KAAKzB,KAAK,CAACgE,UAAU,EAAE;MAC1DxB,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOwC,EAAE;IACX;IAEA,OAAOxB,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASwC,EAAE,CAACxC,IAAI,EAAE;IAChB,IAAIA,IAAI,KAAKzB,KAAK,CAAC+D,UAAU,IAAItC,IAAI,KAAKzB,KAAK,CAACgE,UAAU,EAAE;MAC1DxB,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOyC,CAAC;IACV;IAEA,OAAOzB,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASyC,CAAC,CAACzC,IAAI,EAAE;IACf,IAAIA,IAAI,KAAKzB,KAAK,CAACmE,UAAU,IAAI1C,IAAI,KAAKzB,KAAK,CAACoE,UAAU,EAAE;MAC1D5B,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAO4C,CAAC;IACV;IAEA,OAAO5B,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAAS4C,CAAC,CAAC5C,IAAI,EAAE;IACf,IAAIA,IAAI,KAAKzB,KAAK,CAACsE,UAAU,IAAI7C,IAAI,KAAKzB,KAAK,CAACuE,UAAU,EAAE;MAC1D/B,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOG,KAAK;IACd;IAEA,OAAOA,KAAK,CAACH,IAAI,CAAC;EACpB;;EAEA;EACA,SAASG,KAAK,CAACH,IAAI,EAAE;IACnB,IAAIA,IAAI,KAAKzB,KAAK,CAAC4B,KAAK,EAAE;MACxBY,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAO+C,MAAM;IACf;IAEA,OAAO/B,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAAS+C,MAAM,CAAC/C,IAAI,EAAE;IACpB,IAAIA,IAAI,KAAKzB,KAAK,CAACyE,KAAK,EAAE;MACxBjC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOiD,MAAM;IACf;IAEA,OAAOjC,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASiD,MAAM,CAACjD,IAAI,EAAE;IACpB,IAAIA,IAAI,KAAKzB,KAAK,CAACyE,KAAK,EAAE;MACxBjC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOkD,KAAK;IACd;IAEA,OAAOlC,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASkD,KAAK,CAAClD,IAAI,EAAE;IACnB,OAAOA,IAAI,KAAKzB,KAAK,CAAC4E,GAAG,IACvBlF,YAAY,CAAC+B,IAAI,CAAC,IAClB1B,iBAAiB,CAAC0B,IAAI,CAAC,IACvB3B,kBAAkB,CAAC2B,IAAI,CAAC,GACtBgB,GAAG,CAAChB,IAAI,CAAC,GACTe,OAAO,CAACqB,OAAO,CAACxD,MAAM,EAAEmC,OAAO,CAACqB,OAAO,CAACtD,IAAI,EAAEgD,IAAI,CAAC,EAAEd,GAAG,CAAC,CAAChB,IAAI,CAAC;EACrE;;EAEA;EACA,SAAS8B,IAAI,CAAC9B,IAAI,EAAE;IAClBe,OAAO,CAACoB,IAAI,CAAC,qBAAqB,CAAC;IACnCpB,OAAO,CAACoB,IAAI,CAAC,iBAAiB,CAAC;IAC/B,OAAOtE,EAAE,CAACmC,IAAI,CAAC;EACjB;AACF;;AAEA;AACA,SAAStB,WAAW,CAACqC,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EACrC,OAAOI,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACpB,IAAI,EAAE;IACnBlC,MAAM,CACJkC,IAAI,KAAKzB,KAAK,CAACsC,UAAU,IAAIb,IAAI,KAAKzB,KAAK,CAACuC,UAAU,EACtD,cAAc,CACf;IACDC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOoD,EAAE;EACX;;EAEA;EACA,SAASA,EAAE,CAACpD,IAAI,EAAE;IAChB,IAAIA,IAAI,KAAKzB,KAAK,CAACsC,UAAU,IAAIb,IAAI,KAAKzB,KAAK,CAACuC,UAAU,EAAE;MAC1DC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOqD,EAAE;IACX;IAEA,OAAOrC,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASqD,EAAE,CAACrD,IAAI,EAAE;IAChB,IAAIA,IAAI,KAAKzB,KAAK,CAACsC,UAAU,IAAIb,IAAI,KAAKzB,KAAK,CAACuC,UAAU,EAAE;MAC1DC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOS,GAAG;IACZ;IAEA,OAAOO,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASS,GAAG,CAACT,IAAI,EAAE;IACjB,IAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAG,EAAE;MACtBM,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOkD,KAAK;IACd;IAEA,OAAOlC,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASkD,KAAK,CAAClD,IAAI,EAAE;IACnB,OAAOA,IAAI,KAAKzB,KAAK,CAAC4E,GAAG,IAAI/E,kBAAkB,CAAC4B,IAAI,CAAC,GAAGgB,GAAG,CAAChB,IAAI,CAAC,GAAGnC,EAAE,CAACmC,IAAI,CAAC;EAC9E;AACF;;AAEA;AACA,SAASnB,cAAc,CAACkC,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EACxC;EACA,IAAIsC,0BAA0B;EAC9B;EACA,IAAIC,8BAA8B;EAElC,OAAO3E,MAAM;;EAEb;EACA,SAASA,MAAM,CAACoB,IAAI,EAAE;IACpB,IAAIA,IAAI,KAAKzB,KAAK,CAACiF,SAAS,EAAE;MAC5B,OAAOzC,OAAO,CAACc,KAAK,CAClB3C,uBAAuB,EACvB4C,IAAI,EACJ2B,uBAAuB,CACxB,CAACzD,IAAI,CAAC;IACT;IAEA,IAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAG,IAAIT,IAAI,KAAKzB,KAAK,CAACmC,UAAU,EAAE;MACnD,OAAOK,OAAO,CAACc,KAAK,CAAC7C,WAAW,EAAE8C,IAAI,EAAE2B,uBAAuB,CAAC,CAACzD,IAAI,CAAC;IACxE;;IAEA;IACA;IACA;IACA;IACA;IACA,IACEA,IAAI,KAAKzB,KAAK,CAAC4E,GAAG,IAClBlF,YAAY,CAAC+B,IAAI,CAAC,IAClB1B,iBAAiB,CAAC0B,IAAI,CAAC,IACtBA,IAAI,KAAKzB,KAAK,CAACiC,IAAI,IAAInC,kBAAkB,CAAC2B,IAAI,CAAE,EACjD;MACA,OAAO8B,IAAI,CAAC9B,IAAI,CAAC;IACnB;IAEAe,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOpB,MAAM;EACf;;EAEA;EACA,SAAS6E,uBAAuB,CAACzD,IAAI,EAAE;IACrC,IAAIA,IAAI,KAAKzB,KAAK,CAACkC,GAAG,EAAE;MACtB8C,8BAA8B,GAAGD,0BAA0B;MAC3DA,0BAA0B,GAAGrB,SAAS;MACtClB,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOpB,MAAM;IACf;IAEA,IAAIoB,IAAI,KAAKzB,KAAK,CAACmC,UAAU,EAAE4C,0BAA0B,GAAG,IAAI;IAEhEvC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOpB,MAAM;EACf;;EAEA;EACA,SAASkD,IAAI,CAAC9B,IAAI,EAAE;IAClB,IAAI,CAACuD,8BAA8B,IAAI,CAACD,0BAA0B,EAAE;MAClE,OAAOzF,EAAE,CAACmC,IAAI,CAAC;IACjB;IAEA,OAAOgB,GAAG,CAAChB,IAAI,CAAC;EAClB;AACF;;AAEA;AACA,SAASjB,YAAY,CAACgC,OAAO,EAAElD,EAAE,EAAE;EACjC,IAAI6F,OAAO,GAAG,CAAC;EAEf,OAAOC,MAAM;;EAEb;EACA,SAASA,MAAM,CAAC3D,IAAI,EAAE;IACpB,IAAIA,IAAI,KAAKzB,KAAK,CAACiF,SAAS,EAAE;MAC5B,OAAOzC,OAAO,CAACc,KAAK,CAClB3C,uBAAuB,EACvBrB,EAAE,EACF+F,oBAAoB,CACrB,CAAC5D,IAAI,CAAC;IACT;IAEA,IAAIA,IAAI,KAAKzB,KAAK,CAACsF,eAAe,EAAE;MAClCH,OAAO,EAAE;IACX;IAEA,IAAI1D,IAAI,KAAKzB,KAAK,CAACuF,gBAAgB,EAAE;MACnC,OAAO/C,OAAO,CAACc,KAAK,CAClB7C,WAAW,EACX+E,cAAc,EACdH,oBAAoB,CACrB,CAAC5D,IAAI,CAAC;IACT;IAEA,IAAIgE,OAAO,CAAChE,IAAI,CAAC,EAAE;MACjB,OAAOnC,EAAE,CAACmC,IAAI,CAAC;IACjB;IAEA,IAAIiE,mBAAmB,CAACjE,IAAI,CAAC,EAAE;MAC7B,OAAOe,OAAO,CAACc,KAAK,CAAC7C,WAAW,EAAEnB,EAAE,EAAE+F,oBAAoB,CAAC,CAAC5D,IAAI,CAAC;IACnE;IAEAe,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAO2D,MAAM;EACf;;EAEA;EACA,SAASC,oBAAoB,CAAC5D,IAAI,EAAE;IAClCe,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAO2D,MAAM;EACf;;EAEA;EACA,SAASI,cAAc,CAAC/D,IAAI,EAAE;IAC5B0D,OAAO,EAAE;IACT,OAAOA,OAAO,GAAG,CAAC,GAAG7F,EAAE,CAACmC,IAAI,CAAC,GAAG4D,oBAAoB,CAAC5D,IAAI,CAAC;EAC5D;AACF;;AAEA;AACA,SAASb,+BAA+B,CAAC4B,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EACzD,OAAOI,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACpB,IAAI,EAAE;IACnBlC,MAAM,CAACkC,IAAI,KAAKzB,KAAK,CAACiF,SAAS,EAAE,cAAc,CAAC;IAChDzC,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOkE,MAAM;EACf;;EAEA;EACA,SAASA,MAAM,CAAClE,IAAI,EAAE;IACpB,IAAIjC,UAAU,CAACiC,IAAI,CAAC,EAAE;MACpBe,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOkE,MAAM;IACf;IAEA,IAAIlE,IAAI,KAAKzB,KAAK,CAAC4F,SAAS,EAAE;MAC5BpD,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOkD,KAAK;IACd;IAEA,OAAOlC,GAAG,CAAChB,IAAI,CAAC;EAClB;;EAEA;EACA,SAASkD,KAAK,CAAClD,IAAI,EAAE;IACnB;IACA;IACA,OAAOgE,OAAO,CAAChE,IAAI,CAAC,GAAGnC,EAAE,CAACmC,IAAI,CAAC,GAAGgB,GAAG,CAAChB,IAAI,CAAC;EAC7C;AACF;;AAEA;AACA,SAASf,mBAAmB,CAAC8B,OAAO,EAAElD,EAAE,EAAEmD,GAAG,EAAE;EAC7C,OAAOI,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACpB,IAAI,EAAE;IACnBlC,MAAM,CACJkC,IAAI,KAAKzB,KAAK,CAACiC,IAAI,IAAIyD,mBAAmB,CAACjE,IAAI,CAAC,EAChD,sBAAsB,CACvB;IACDe,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;IACrB,OAAOkD,KAAK;EACd;;EAEA;EACA,SAASA,KAAK,CAAClD,IAAI,EAAE;IACnB;IACA,IAAIiE,mBAAmB,CAACjE,IAAI,CAAC,EAAE;MAC7Be,OAAO,CAACW,OAAO,CAAC1B,IAAI,CAAC;MACrB,OAAOkD,KAAK;IACd;;IAEA;IACA;IACA,OAAOc,OAAO,CAAChE,IAAI,CAAC,GAAGnC,EAAE,CAACmC,IAAI,CAAC,GAAGgB,GAAG,CAAChB,IAAI,CAAC;EAC7C;AACF;;AAEA;AACA;AACA;AACA;AACA,SAASiE,mBAAmB,CAACjE,IAAI,EAAE;EACjC,OACEA,IAAI,KAAKzB,KAAK,CAAC6F,eAAe,IAC9BpE,IAAI,KAAKzB,KAAK,CAAC8F,aAAa,IAC5BrE,IAAI,KAAKzB,KAAK,CAAC+F,UAAU,IACzBtE,IAAI,KAAKzB,KAAK,CAACuF,gBAAgB,IAC/B9D,IAAI,KAAKzB,KAAK,CAACgG,QAAQ,IACvBvE,IAAI,KAAKzB,KAAK,CAACiG,KAAK,IACpBxE,IAAI,KAAKzB,KAAK,CAACkC,GAAG,IAClBT,IAAI,KAAKzB,KAAK,CAAC4B,KAAK,IACpBH,IAAI,KAAKzB,KAAK,CAAC4F,SAAS,IACxBnE,IAAI,KAAKzB,KAAK,CAACkG,QAAQ,IACvBzE,IAAI,KAAKzB,KAAK,CAACmG,YAAY,IAC3B1E,IAAI,KAAKzB,KAAK,CAACmC,UAAU,IACzBV,IAAI,KAAKzB,KAAK,CAACoG,KAAK;AAExB;;AAEA;AACA;AACA;AACA;AACA,SAASX,OAAO,CAAChE,IAAI,EAAE;EACrB,OACEA,IAAI,KAAKzB,KAAK,CAAC4E,GAAG,IAClBnD,IAAI,KAAKzB,KAAK,CAACkG,QAAQ,IACvBtG,yBAAyB,CAAC6B,IAAI,CAAC;AAEnC;;AAEA;AACA;AACA;AACA;AACA,SAASqB,QAAQ,CAACrB,IAAI,EAAE;EACtB,OACEA,IAAI,KAAKzB,KAAK,CAACgC,QAAQ,IACvBP,IAAI,KAAKzB,KAAK,CAACiC,IAAI,IACnBR,IAAI,KAAKzB,KAAK,CAACkC,GAAG,IAClBT,IAAI,KAAKzB,KAAK,CAACmC,UAAU,IACzB1C,iBAAiB,CAACgC,IAAI,CAAC;AAE3B;;AAEA;AACA,SAAST,WAAW,CAACS,IAAI,EAAE;EACzB,OACEA,IAAI,KAAKzB,KAAK,CAAC4E,GAAG,IAClBnD,IAAI,KAAKzB,KAAK,CAACsF,eAAe,IAC9B7D,IAAI,KAAKzB,KAAK,CAACgG,QAAQ,IACvBvE,IAAI,KAAKzB,KAAK,CAACmC,UAAU,IACzBV,IAAI,KAAKzB,KAAK,CAACoG,KAAK,IACpBxG,yBAAyB,CAAC6B,IAAI,CAAC;AAEnC;;AAEA;AACA,SAASN,YAAY,CAACM,IAAI,EAAE;EAC1B,OAAOA,IAAI,KAAKzB,KAAK,CAAC4E,GAAG,IAAI,CAACpF,UAAU,CAACiC,IAAI,CAAC;AAChD;;AAEA;AACA,SAASH,aAAa,CAACG,IAAI,EAAE;EAC3B,OAAOA,IAAI,KAAKzB,KAAK,CAACyE,KAAK,IAAItD,YAAY,CAACM,IAAI,CAAC;AACnD;;AAEA;AACA;AACA;AACA;AACA,SAASsB,kBAAkB,CAACC,MAAM,EAAE;EAClC,IAAIqD,KAAK,GAAGrD,MAAM,CAACsD,MAAM;EACzB,IAAIC,MAAM,GAAG,KAAK;EAElB,OAAOF,KAAK,EAAE,EAAE;IACd,MAAMG,KAAK,GAAGxD,MAAM,CAACqD,KAAK,CAAC,CAAC,CAAC,CAAC;IAE9B,IACE,CAACG,KAAK,CAACC,IAAI,KAAK,WAAW,IAAID,KAAK,CAACC,IAAI,KAAK,YAAY,KAC1D,CAACD,KAAK,CAACE,SAAS,EAChB;MACAH,MAAM,GAAG,IAAI;MACb;IACF;;IAEA;IACA;IACA,IAAIC,KAAK,CAACG,6BAA6B,EAAE;MACvCJ,MAAM,GAAG,KAAK;MACd;IACF;EACF;EAEA,IAAIvD,MAAM,CAACsD,MAAM,GAAG,CAAC,IAAI,CAACC,MAAM,EAAE;IAChC;IACA;IACAvD,MAAM,CAACA,MAAM,CAACsD,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACK,6BAA6B,GAAG,IAAI;EACnE;EAEA,OAAOJ,MAAM;AACf"},"metadata":{},"sourceType":"module","externalDependencies":[]}